# ImplementaÃ§Ã£o de IA Generativa para Entrevistas

## ğŸ¯ Objetivo

Remover todo o hardcoding de perguntas e implementar geraÃ§Ã£o dinÃ¢mica e inteligente usando **AWS Bedrock (Claude 3.5 Sonnet)** baseada no contexto real da vaga.

## âœ… O que foi implementado

### 1. **Novo Lambda de IA (`interview-ai`)**
- **LocalizaÃ§Ã£o**: `backend/lambdas/interview-ai/`
- **Modelo**: Claude 3.5 Sonnet (anthropic.claude-3-5-sonnet-20241022-v2:0)
- **Timeout**: 90 segundos
- **MemÃ³ria**: 2048 MB

**Funcionalidades**:
- âœ… `generateInitialQuestions`: Gera perguntas iniciais personalizadas baseadas na descriÃ§Ã£o da vaga
- âœ… `generateFollowUp`: Cria follow-ups contextuais baseados na resposta do candidato
- âœ… `evaluateAnswer`: Avalia semanticamente a qualidade da resposta
- âœ… `generateNewQuestions`: Gera novas perguntas adaptadas ao progresso da entrevista

**Prompts Inteligentes**:
- Analisa descriÃ§Ã£o da vaga para identificar:
  - Tecnologias obrigatÃ³rias vs desejÃ¡veis
  - NÃ­vel de senioridade (jÃºnior, pleno, sÃªnior)
  - Ãreas de foco (backend, frontend, fullstack, devops, etc)
  - Responsabilidades principais
- Gera perguntas especÃ­ficas (nÃ£o genÃ©ricas)
- Adapta dificuldade ao cargo
- Inclui perguntas tÃ©cnicas e comportamentais

### 2. **ServiÃ§o Frontend Reescrito (`interviewAIService.ts`)**
- **Antes**: Banco hardcoded com ~500 perguntas tÃ©cnicas
- **Depois**: Chamadas assÃ­ncronas para API de IA

**MudanÃ§as**:
- âŒ Removido: `technicalQuestionsBank` (banco de perguntas hardcoded)
- âŒ Removido: `techCategoryMap` (mapeamento de tecnologias)
- âŒ Removido: `extractJobRequirements` (parsing manual)
- âœ… Adicionado: FunÃ§Ãµes assÃ­ncronas que chamam Bedrock
- âœ… Adicionado: Cache de 30 segundos para evitar chamadas duplicadas
- âœ… Adicionado: Tratamento de erros robusto

### 3. **Hook Atualizado (`useInterviewAssistant.ts`)**
- Todas as chamadas sÃ­ncronas convertidas para assÃ­ncronas
- GeraÃ§Ã£o de perguntas iniciais com loading state
- Follow-ups automÃ¡ticos apÃ³s detecÃ§Ã£o de pergunta
- AvaliaÃ§Ã£o de respostas com feedback da IA
- GeraÃ§Ã£o progressiva de novas perguntas

### 4. **IntegraÃ§Ã£o no Lambda Principal (`chime-meeting`)**
- Novo handler: `handleInterviewAI`
- Faz proxy para o Lambda de IA
- Rota: `POST /interview/ai`
- ValidaÃ§Ã£o de aÃ§Ãµes permitidas
- Logging estruturado

### 5. **Infraestrutura Atualizada (`complete-stack.yaml`)**
- âœ… Novo Lambda: `InterviewAIFunction`
- âœ… Novo Lambda: `ChimeMeetingFunction` (adicionado ao template)
- âœ… PermissÃµes Bedrock configuradas
- âœ… VariÃ¡vel de ambiente: `INTERVIEW_AI_LAMBDA`
- âœ… Rotas HTTP configuradas no Recording API
- âœ… PermissÃµes Lambda para invocaÃ§Ã£o

## ğŸ“‹ Arquivos Modificados

### Backend
1. âœ… `backend/lambdas/interview-ai/index.js` (NOVO)
2. âœ… `backend/lambdas/interview-ai/package.json` (NOVO)
3. âœ… `backend/lambdas/chime-meeting/index.js` (handler + rota)
4. âœ… `infrastructure/complete-stack.yaml` (Lambda + rotas)

### Frontend
1. âœ… `frontend/src/services/interviewAIService.ts` (reescrito)
2. âœ… `frontend/src/hooks/useInterviewAssistant.ts` (async)

## ğŸš€ Como Funciona Agora

### Fluxo de GeraÃ§Ã£o de Perguntas

```
1. UsuÃ¡rio cria entrevista
   â”œâ”€ Informa: Cargo (ex: "Desenvolvedor Full Stack SÃªnior")
   â””â”€ Informa: DescriÃ§Ã£o completa da vaga

2. Frontend chama: generateInitialQuestions
   â”œâ”€ Envia contexto completo para Bedrock
   â”œâ”€ IA analisa requisitos da vaga
   â”œâ”€ IA identifica tecnologias e nÃ­vel
   â””â”€ IA gera 3 perguntas personalizadas

3. Durante a entrevista:
   â”œâ”€ DetecÃ§Ã£o automÃ¡tica de pergunta feita
   â”œâ”€ AvaliaÃ§Ã£o da resposta do candidato
   â”œâ”€ GeraÃ§Ã£o de follow-up se resposta incompleta
   â””â”€ Novas perguntas a cada N respostas

4. AvaliaÃ§Ã£o contÃ­nua:
   â”œâ”€ Score de 0-100
   â”œâ”€ Qualidade: excellent/good/basic/incomplete
   â”œâ”€ Feedback construtivo
   â”œâ”€ Pontos fortes identificados
   â””â”€ Ãreas de melhoria sugeridas
```

### Exemplo de Prompt Enviado ao Bedrock

```
VocÃª Ã© um especialista em recrutamento tÃ©cnico. Sua tarefa Ã© gerar 3 perguntas 
PERSONALIZADAS para uma entrevista de emprego.

CONTEXTO DA VAGA:
- Cargo: Desenvolvedor Full Stack SÃªnior
- DescriÃ§Ã£o completa: Buscamos desenvolvedor com 5+ anos de experiÃªncia em React, 
  Node.js, TypeScript, AWS. ExperiÃªncia com arquitetura de microserviÃ§os, Docker, 
  Kubernetes. DesejÃ¡vel: GraphQL, Redis, MongoDB.

INSTRUÃ‡Ã•ES:
1. Analise cuidadosamente a descriÃ§Ã£o da vaga para identificar:
   - Tecnologias obrigatÃ³rias e desejÃ¡veis
   - NÃ­vel de senioridade
   - Responsabilidades principais
   - Soft skills necessÃ¡rias

2. Gere 3 perguntas que:
   - Sejam ESPECÃFICAS para esta vaga (nÃ£o genÃ©ricas)
   - Avaliem as competÃªncias tÃ©cnicas mencionadas
   - Tenham dificuldade apropriada (sÃªnior = intermediate/advanced)
   - Sejam abertas e permitam demonstrar conhecimento
   - Incluam pelo menos 1 pergunta comportamental

3. Para cada pergunta, forneÃ§a:
   - A pergunta em si
   - Categoria (technical, behavioral, experience, situational)
   - Dificuldade (basic, intermediate, advanced)
   - Tecnologia/Ã¡rea especÃ­fica
   - Pontos-chave que uma boa resposta deveria abordar

FORMATO DE RESPOSTA (JSON):
{
  "questions": [
    {
      "question": "Como vocÃª estruturaria uma arquitetura de microserviÃ§os...",
      "category": "technical",
      "difficulty": "advanced",
      "technology": "architecture",
      "expectedTopics": ["API Gateway", "Service Discovery", "Event-driven"],
      "context": "Avalia experiÃªncia com arquitetura distribuÃ­da"
    }
  ]
}
```

## ğŸ”§ ConfiguraÃ§Ã£o NecessÃ¡ria

### PermissÃµes IAM

O Lambda `InterviewAIFunction` precisa de:
```yaml
- bedrock:InvokeModel
- bedrock:InvokeModelWithResponseStream
```

### VariÃ¡veis de Ambiente

No `ChimeMeetingFunction`:
```yaml
INTERVIEW_AI_LAMBDA: !GetAtt InterviewAIFunction.Arn
```

### Modelo Bedrock

- **Modelo**: `anthropic.claude-3-5-sonnet-20241022-v2:0`
- **RegiÃ£o**: us-east-1
- **Acesso**: Deve estar habilitado no console AWS Bedrock

## ğŸ“¦ Deploy

### 1. Instalar dependÃªncias do novo Lambda

```bash
cd backend/lambdas/interview-ai
npm install
cd ../../..
```

### 2. Build e Deploy do Backend

```bash
# Build
sam build --template-file infrastructure/complete-stack.yaml

# Deploy
sam deploy --config-file samconfig.toml --no-confirm-changeset
```

### 3. Build e Deploy do Frontend

```bash
# Build
cd frontend && npm run build

# Deploy para S3
aws s3 sync dist/ s3://chat-colaborativo-prod-frontend-383234048592 --delete

# Invalidar cache CloudFront
aws cloudfront create-invalidation --distribution-id E19FZWDK7MJWSX --paths "/*"
```

## ğŸ§ª Testando

### 1. Criar uma entrevista

```javascript
// No frontend, ao criar reuniÃ£o:
{
  meetingType: 'ENTREVISTA',
  topic: 'Desenvolvedor Full Stack SÃªnior',
  jobDescription: `
    Buscamos desenvolvedor com 5+ anos de experiÃªncia.
    
    ObrigatÃ³rio:
    - React, Node.js, TypeScript
    - AWS (Lambda, DynamoDB, S3)
    - Docker, Kubernetes
    
    DesejÃ¡vel:
    - GraphQL, Redis, MongoDB
    - ExperiÃªncia com arquitetura de microserviÃ§os
  `
}
```

### 2. Verificar logs do Lambda

```bash
# Logs do Interview AI
aws logs tail /aws/lambda/chat-colaborativo-serverless-InterviewAIFunction --follow

# Logs do Chime Meeting
aws logs tail /aws/lambda/chat-colaborativo-serverless-chime-meeting --follow
```

### 3. Testar API diretamente

```bash
curl -X POST https://y08b6lfdel.execute-api.us-east-1.amazonaws.com/prod/interview/ai \
  -H "Content-Type: application/json" \
  -d '{
    "action": "generateInitialQuestions",
    "context": {
      "meetingType": "ENTREVISTA",
      "topic": "Desenvolvedor Full Stack SÃªnior",
      "jobDescription": "Buscamos desenvolvedor com 5+ anos...",
      "transcriptionHistory": [],
      "questionsAsked": []
    },
    "count": 3
  }'
```

## ğŸ¯ BenefÃ­cios

### Antes (Hardcoded)
- âŒ Perguntas genÃ©ricas
- âŒ NÃ£o considera contexto da vaga
- âŒ Banco limitado (~500 perguntas)
- âŒ AvaliaÃ§Ã£o por keywords simples
- âŒ Sem adaptaÃ§Ã£o ao progresso

### Depois (IA Generativa)
- âœ… Perguntas personalizadas para cada vaga
- âœ… Analisa descriÃ§Ã£o completa
- âœ… Infinitas possibilidades de perguntas
- âœ… AvaliaÃ§Ã£o semÃ¢ntica inteligente
- âœ… Adapta-se ao contexto da conversa
- âœ… Follow-ups contextuais
- âœ… Feedback construtivo

## ğŸ“Š Custos Estimados

### AWS Bedrock (Claude 3.5 Sonnet)
- **Input**: $0.003 por 1K tokens
- **Output**: $0.015 por 1K tokens

**Estimativa por entrevista**:
- Perguntas iniciais: ~2K tokens input + 500 tokens output = $0.01
- Follow-ups (3x): ~1.5K tokens input + 300 tokens output = $0.01
- AvaliaÃ§Ãµes (5x): ~1K tokens input + 200 tokens output = $0.01
- **Total por entrevista**: ~$0.03

**Para 100 entrevistas/mÃªs**: ~$3.00

### Lambda
- Interview AI: 90s timeout, 2048MB = ~$0.0003 por invocaÃ§Ã£o
- **Total por entrevista**: ~$0.003 (10 invocaÃ§Ãµes)

**Custo total estimado**: $3.30/mÃªs para 100 entrevistas

## ğŸ”’ SeguranÃ§a

- âœ… ValidaÃ§Ã£o de aÃ§Ãµes permitidas
- âœ… Timeout configurado (90s)
- âœ… Rate limiting no API Gateway
- âœ… CORS configurado
- âœ… Logs estruturados
- âœ… Tratamento de erros robusto
- âœ… Cache para evitar chamadas duplicadas

## ğŸ“ PrÃ³ximos Passos (Opcional)

1. **AnÃ¡lise de sentimento**: Avaliar tom e confianÃ§a do candidato
2. **ComparaÃ§Ã£o entre candidatos**: Ranking automÃ¡tico
3. **RelatÃ³rio final**: Resumo executivo da entrevista
4. **Perguntas em mÃºltiplos idiomas**: Suporte internacional
5. **Fine-tuning**: Treinar modelo especÃ­fico para sua empresa

## ğŸ› Troubleshooting

### Erro: "Bedrock model not found"
- Verificar se o modelo estÃ¡ habilitado no console Bedrock
- RegiÃ£o correta: us-east-1

### Erro: "Lambda timeout"
- Aumentar timeout do InterviewAIFunction (jÃ¡ estÃ¡ em 90s)
- Verificar se Bedrock estÃ¡ respondendo

### Perguntas nÃ£o aparecem
- Verificar logs do Lambda
- Verificar se INTERVIEW_AI_LAMBDA estÃ¡ configurado
- Testar API diretamente com curl

### Cache muito agressivo
- Ajustar CACHE_TTL em interviewAIService.ts (padrÃ£o: 30s)
- Limpar cache: `interviewAIService.clearCache()`

## ğŸ“š ReferÃªncias

- [AWS Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [Claude 3.5 Sonnet Model Card](https://www.anthropic.com/claude)
- [SAM CLI Reference](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-command-reference.html)
